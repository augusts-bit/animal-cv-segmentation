{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghjJogKiacRJ"
      },
      "outputs": [],
      "source": [
        "# Based on https://github.com/computervisioneng/image-segmentation-yolov8/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c--7Z8jjCnwi"
      },
      "source": [
        "### Check what classes (soorten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRjuzcP6CmiG"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import re\n",
        "\n",
        "ann_dir = \"gdrive/My Drive/Stage/ClassificationData/Ready/10m/0bg/annotations\"\n",
        "ann_files = sorted([f for f in os.listdir(ann_dir) if f.endswith('.txt')])\n",
        "\n",
        "def get_classes_sizes(ann_files):\n",
        "\n",
        "  categories = []\n",
        "  min_width = float('inf')\n",
        "  min_height = float('inf')\n",
        "\n",
        "  for ann_file in ann_files:\n",
        "\n",
        "        # Get annotations: bounding box, segmentation (mask) and label\n",
        "          with open(os.path.join(ann_dir, ann_file), \"r\") as file:\n",
        "              annotations = file.readlines()\n",
        "\n",
        "              # Get category\n",
        "              for annotation in annotations:\n",
        "                  # Process each line in the file\n",
        "                  if annotation.startswith('Original label'):\n",
        "\n",
        "                      # Extract category\n",
        "                      match = re.search(r'Original label for object \\d+ : \"(.*?)\"', annotation)\n",
        "                      if match:\n",
        "                          label = match.group(1)\n",
        "                          categories.append(label)\n",
        "\n",
        "              # Join lines into a single string\n",
        "              annotations_str = ''.join(annotations)\n",
        "\n",
        "              # Use regular expressions to extract width and height\n",
        "              width_match = re.search(r'Image size \\(X x Y\\) : (\\d+) x (\\d+)', annotations_str)\n",
        "              if width_match:\n",
        "                  width = int(width_match.group(1))\n",
        "                  height = int(width_match.group(2))\n",
        "\n",
        "                  # Update the minimum width and height if necessary\n",
        "                  min_width = min(min_width, width)\n",
        "                  min_height = min(min_height, height)\n",
        "\n",
        "  # Return categories and sizes\n",
        "  return categories, min_width, min_height\n",
        "\n",
        "categories, min_width, min_height = get_classes_sizes(ann_files)\n",
        "soorten = sorted(list(set(categories)))\n",
        "print(\"Dataset contains:\", soorten)\n",
        "print(\"Minimum width and heigth:\", min_width, \"x\", min_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKy_2AtbaWzE"
      },
      "source": [
        "### Create YOLO labels\n",
        "see https://docs.ultralytics.com/datasets/segment/#ultralytics-yolo-format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThZ9dydCKNVo",
        "outputId": "bdf0ea63-3408-4240-a0df-535dc9b83637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the class labels (soorten)\n",
        "class_labels = ['anders', 'dwergmeeuw', 'grote stern', 'kluut', 'kokmeeuw', 'visdief', 'zwartkopmeeuw']\n",
        "\n",
        "mask_dir = \"/content/gdrive/MyDrive/Stage/ClassificationData/Ready/5m/0bg/masks\"\n",
        "annotation_dir = \"/content/gdrive/MyDrive/Stage/ClassificationData/Ready/5m/0bg/annotations\"\n",
        "output_dir = \"/content/gdrive/MyDrive/Stage/ClassificationData/Ready/5m/0bg/labels\"\n",
        "\n",
        "for annotation_file in sorted(os.listdir(annotation_dir)):\n",
        "    if annotation_file.endswith('.txt'):\n",
        "        annotation_path = os.path.join(annotation_dir, annotation_file)\n",
        "        image_path = annotation_path.replace(\"_annotation\", \"_mask\").replace(\".txt\", \".png\")\n",
        "\n",
        "        # Read class labels and bounding boxes from annotation file\n",
        "        with open(annotation_path, 'r') as ann_file:\n",
        "            ann_content = ann_file.read()\n",
        "\n",
        "            # Use regex to find the number of objects\n",
        "            match = re.search(r'Objects with ground truth : (\\d+)', ann_content)\n",
        "            if match:\n",
        "                num_objects = int(match.group(1))\n",
        "            else:\n",
        "                num_objects = 0\n",
        "\n",
        "            # Initialize lists to store polygons and class indices for all objects\n",
        "            all_polygons = []\n",
        "            all_class_indices = []\n",
        "\n",
        "            # Process each object in the annotation file\n",
        "            for i in range(num_objects):\n",
        "                original_label_match = re.search(r'Original label for object {} : \"(.*?)\"'.format(i + 1), ann_content)\n",
        "                bbox_coords_match = re.search(r'Bounding box for object {} : \\(Xmin, Ymin\\) - \\(Xmax, Ymax\\) : \\((\\d+), (\\d+)\\) - \\((\\d+), (\\d+)\\)'.format(i + 1), ann_content)\n",
        "                # mask_path_match = re.search(r'Pixel mask for object {} : \"(.*?)\"'.format(i + 1), ann_content)\n",
        "\n",
        "                if original_label_match and bbox_coords_match: # and mask_path_match:\n",
        "                    original_label = original_label_match.group(1)\n",
        "                    bbox_coords = map(int, bbox_coords_match.groups())\n",
        "                    mask_name = annotation_file.replace(\"annotation\", \"mask\")\n",
        "                    mask_path = os.path.join(mask_dir, mask_name[:-4]+\".png\")\n",
        "\n",
        "                    class_index = class_labels.index(original_label)\n",
        "\n",
        "                    # Load the binary mask and get its contours\n",
        "                    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                    H, W = mask.shape\n",
        "                    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                    # Convert the contours to polygons\n",
        "                    all_polygons_per_object = []\n",
        "                    cnt = contours[i] # only use the contour of the current object\n",
        "                    if cv2.contourArea(cnt) > 0:\n",
        "                        polygon = []\n",
        "                        for point in cnt:\n",
        "                            x, y = point[0]\n",
        "                            polygon.append(x / W)\n",
        "                            polygon.append(y / H)\n",
        "                        all_polygons_per_object.append(polygon)\n",
        "\n",
        "                    # Append polygons and class index to the lists\n",
        "                    all_polygons.extend(all_polygons_per_object)\n",
        "                    test_polygons = all_polygons\n",
        "                    all_class_indices.extend([class_index] * len(all_polygons_per_object))\n",
        "\n",
        "            # Print all polygons with corresponding class indices to a single YOLO label file\n",
        "            img_name = annotation_file.replace(\"annotation\", \"img\") # label needs to have the same name as the img\n",
        "            with open(os.path.join(output_dir, '{}.txt'.format(img_name[:-4])), 'w') as f:\n",
        "                for class_index, polygon in zip(all_class_indices, all_polygons):\n",
        "                    line = '{} {}'.format(class_index, ' '.join(map(str, polygon)))\n",
        "                    f.write('{}\\n'.format(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1GXyK8HDArQ"
      },
      "source": [
        "### See if length of files in dataset match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij__7P-aC-NY",
        "outputId": "de3c9136-8b05-4136-f397-09357d3d5529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14221 images 14221 masks 14221 annotations 14221 labels in directory gdrive/My Drive/Stage/ClassificationData/Ready/5m/0bg\n"
          ]
        }
      ],
      "source": [
        "root_path = \"gdrive/My Drive/Stage/ClassificationData/Ready\"\n",
        "\n",
        "# See if number of files match\n",
        "print(len(os.listdir(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"images\"))), \"images\",\n",
        "      len(os.listdir(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"masks\"))), \"masks\",\n",
        "      len(os.listdir(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"annotations\"))), \"annotations\",\n",
        "      len(os.listdir(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"labels\"))), \"labels\",\n",
        "      \"in directory\", os.path.join(root_path, \"5m\", str(0) + \"bg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrNp-w0YHQ_i"
      },
      "source": [
        "### Make config and split files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE-qsjX6HU8T",
        "outputId": "86840fb4-1b3c-49f0-c640-1bf224bcf9a2"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# To avoid error: NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968\n",
        "import locale\n",
        "print(locale.getpreferredencoding())\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "\n",
        "import os, re, random\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "# from utils.datasets import *\n",
        "import yaml\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9grw5N3bI6bI",
        "outputId": "c2cc6d6b-c1ec-40cb-ebf0-b80dc34fc9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autosplitting images from gdrive/My Drive/Stage/ClassificationData/Ready/5m/0bg/images\n"
          ]
        }
      ],
      "source": [
        "# See https://github.com/ultralytics/yolov5/issues/1579\n",
        "\n",
        "root_path = \"gdrive/My Drive/Stage/ClassificationData/Ready\"\n",
        "IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes\n",
        "\n",
        "def img2label_paths(img_paths):\n",
        "    # Define label paths as a function of image paths\n",
        "    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings\n",
        "    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]\n",
        "\n",
        "def autosplit(path, weights, annotated_only=False):\n",
        "    \"\"\" Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files\n",
        "    Usage: from utils.dataloaders import *; autosplit()\n",
        "    Arguments\n",
        "        path:            Path to images directory\n",
        "                        --> assumes that the corresponding labels is in the same parent directory /labels/\n",
        "        weights:         Train, val, test weights (list, tuple)\n",
        "        annotated_only:  Only use images with an annotated txt file\n",
        "    \"\"\"\n",
        "    path = Path(path)  # images dir\n",
        "    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only\n",
        "    n = len(files)  # number of files\n",
        "    random.seed(0)  # for reproducibility\n",
        "    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split\n",
        "\n",
        "    txt = ['autosplit_train.txt', 'autosplit_val.txt', ]  # 2 txt files\n",
        "    for x in txt:\n",
        "        if (path.parent / x).exists():\n",
        "            (path.parent / x).unlink()  # remove existing\n",
        "\n",
        "    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)\n",
        "    for i, img in zip(indices, files):\n",
        "        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label\n",
        "            with open(path.parent / txt[i], 'a') as f:\n",
        "                f.write(f'./{img.relative_to(path.parent).as_posix()}' + '\\n')  # add image to txt file\n",
        "\n",
        "autosplit(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"images\"), weights=(0.9, 0.1, 0.0))\n",
        "\n",
        "class_labels = ['anders', 'dwergmeeuw', 'grote stern', 'kluut', 'kokmeeuw', 'visdief', 'zwartkopmeeuw'] # = soorten\n",
        "\n",
        "data = {\n",
        "    'path': os.path.join(root_path, \"5m\", str(0) + \"bg\"), # root path, start at home directory\n",
        "    'train': \"autosplit_train.txt\",\n",
        "    'val': \"autosplit_val.txt\",\n",
        "    'nc': len(class_labels), # number of classes\n",
        "    'names': class_labels\n",
        "}\n",
        "\n",
        "with open(os.path.join(root_path, \"5m\", str(0) + \"bg\", \"config.yaml\"), 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1698781538647
    }
   },
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1698781541420
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Parameters (make sure these are correct)\n",
    "subscr_id = \"\" \n",
    "resc_name = \"\"\n",
    "worksp_name = \"\"\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential = credential,\n",
    "    subscription_id = subscr_id,\n",
    "    resource_group_name = resc_name,\n",
    "    workspace_name = worksp_name,\n",
    ")\n",
    "\n",
    "# ws \n",
    "# from azureml.core import Workspace\n",
    "# ws = Workspace(subscr_id, resc_name, worksp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1698781544698
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "### First run az login in a command prompt to make sure you have authenticated using the Azure CLI\n",
    "\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_target = \"\"\n",
    "cpu_size = \"\"\n",
    "\n",
    "gpu_compute_target = \"\"\n",
    "gpu_size = \"\"\n",
    "\n",
    "def create_compute(target, size):\n",
    "    try:\n",
    "        # let's see if the compute target already exists\n",
    "        cluster = ml_client.compute.get(target)\n",
    "        print(\n",
    "            f\"You already have a cluster named {target}, we'll reuse it as is.\"\n",
    "        )\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Creating a new compute target...\")\n",
    "\n",
    "        # Let's create the Azure ML compute object with the intended parameters\n",
    "        cluster = AmlCompute(\n",
    "            # Name assigned to the compute cluster\n",
    "            name=target,\n",
    "            # Azure ML Compute is the on-demand VM service\n",
    "            type=\"amlcompute\",\n",
    "            # VM Family\n",
    "            size=size,\n",
    "            # Minimum running nodes when there is no job running\n",
    "            min_instances=0,\n",
    "            # Nodes in cluster\n",
    "            max_instances=4,\n",
    "            # How many seconds will the node running after the job termination\n",
    "            idle_time_before_scale_down=180,\n",
    "            # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "            tier=\"Dedicated\",\n",
    "        )\n",
    "\n",
    "        # Now, we pass the object to MLClient's create_or_update method\n",
    "        cluster = ml_client.begin_create_or_update(cluster).result()\n",
    "\n",
    "    print(\n",
    "        f\"AMLCompute with name {cluster.name} is created, the compute size is {cluster.size}\"\n",
    "    )\n",
    "    \n",
    "    return target\n",
    "    \n",
    "compute_target = create_compute(gpu_compute_target, gpu_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1698781547772
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# For job\n",
    "env_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1698781550742
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "# Load from local\n",
    "root_path = r\"\"\n",
    "data_set = \"\" # Folder in rootpath containing to be used images, masks, annotations (xm/ybg) \n",
    "data_path = os.path.join(root_path, data_set) \n",
    "\n",
    "data_path = r\"\"\n",
    "\n",
    "# Load from data asset \n",
    "# train_data_asset = ml_client.data.get(\"test_dataasset\", version=\"1\") # Split into train and vali in script\n",
    "# data_path = train_data_asset.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1698781554044
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# from azure.ai.ml import command\n",
    "# from azure.ai.ml import Input\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# # Pass hyperparameter values\n",
    "# param = {\n",
    "#     \"iterations\": 30,\n",
    "#     \"learning_rate\": 0.00025,\n",
    "#     \"img_per_batch\": 3, # the real \"batch size\"\n",
    "#     \"roi_batch_size\": 16, # the ROI head \"batch size\"\n",
    "#     \"dataset\": data_set.replace(\"/\", \"-\")\n",
    "# }\n",
    "\n",
    "# # Serialize the dictionary to a JSON file\n",
    "# with open('param.json', 'w') as json_file:\n",
    "#     json.dump(param, json_file)\n",
    "\n",
    "# # Read the contents of param.json to set description of job\n",
    "# with open('param.json', 'r') as json_file:\n",
    "#     description = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1698781560134
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# Set job and run\n",
    "job = command(\n",
    "     code=\".\", \n",
    "     command='python detectron2_train2.py --traindata ${{inputs.train_data}} --iterations ${{inputs.iterations}} --learning_rate ${{inputs.learning_rate}} --img_per_batch ${{inputs.img_per_batch}} --roi_batch_size ${{inputs.roi_batch_size}}' ,\n",
    "     inputs={\n",
    "         \"train_data\": Input(path=data_path,\n",
    "             type=AssetTypes.URI_FOLDER,\n",
    "             mode=InputOutputModes.RO_MOUNT # Mount (.RO_MOUNT) or download (.DOWNLOAD)\n",
    "         ),\n",
    "         \"iterations\": 100,\n",
    "         \"learning_rate\": 0.00025,\n",
    "         \"img_per_batch\": 3, # the real \"batch size\"\n",
    "         \"roi_batch_size\": 16, # the ROI head \"batch size\"\n",
    "     },\n",
    "     compute=compute_target,\n",
    "     environment=env_name,\n",
    "     outputs={},  # Add any required outputs here\n",
    "     description=\"Detectron2 training. See job yaml for parameters.\"\n",
    " )\n",
    "\n",
    "ml_client.jobs.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "\n",
    "job_for_sweep = job(\n",
    "    iterations=Choice(values=[30,100]),\n",
    "    learning_rate=Uniform(min_value=0.0001, max_value=0.0002),\n",
    "    img_per_batch=Choice(values=[3]),\n",
    "    roi_batch_size=Choice(values=[16,32]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = job_for_sweep.sweep(\n",
    "    compute=compute_target,\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"vali_loss\",\n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "\n",
    "# define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=10, timeout=7200)\n",
    "\n",
    "# submit the sweep\n",
    "ml_client.create_or_update(sweep_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

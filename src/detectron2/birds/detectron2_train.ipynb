{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1698781538647
    }
   },
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1698781541420
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Parameters (make sure these are correct)\n",
    "subscr_id = \"\" \n",
    "resc_name = \"\"\n",
    "worksp_name = \"\"\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential = credential,\n",
    "    subscription_id = subscr_id,\n",
    "    resource_group_name = resc_name,\n",
    "    workspace_name = worksp_name,\n",
    ")\n",
    "\n",
    "# ws \n",
    "# from azureml.core import Workspace\n",
    "# ws = Workspace(subscr_id, resc_name, worksp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1698781544698
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "### First run az login in a command prompt to make sure you have authenticated using the Azure CLI\n",
    "\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_target = \"\"\n",
    "cpu_size = \"\"\n",
    "\n",
    "gpu_compute_target = \"\"\n",
    "gpu_size = \"\"\n",
    "\n",
    "def create_compute(target, size):\n",
    "    try:\n",
    "        # let's see if the compute target already exists\n",
    "        cluster = ml_client.compute.get(target)\n",
    "        print(\n",
    "            f\"You already have a cluster named {target}, we'll reuse it as is.\"\n",
    "        )\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Creating a new compute target...\")\n",
    "\n",
    "        # Let's create the Azure ML compute object with the intended parameters\n",
    "        cluster = AmlCompute(\n",
    "            # Name assigned to the compute cluster\n",
    "            name=target,\n",
    "            # Azure ML Compute is the on-demand VM service\n",
    "            type=\"amlcompute\",\n",
    "            # VM Family\n",
    "            size=size,\n",
    "            # Minimum running nodes when there is no job running\n",
    "            min_instances=0,\n",
    "            # Nodes in cluster\n",
    "            max_instances=4,\n",
    "            # How many seconds will the node running after the job termination\n",
    "            idle_time_before_scale_down=180,\n",
    "            # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "            tier=\"Dedicated\",\n",
    "        )\n",
    "\n",
    "        # Now, we pass the object to MLClient's create_or_update method\n",
    "        cluster = ml_client.begin_create_or_update(cluster).result()\n",
    "\n",
    "    print(\n",
    "        f\"AMLCompute with name {cluster.name} is created, the compute size is {cluster.size}\"\n",
    "    )\n",
    "    \n",
    "    return target\n",
    "    \n",
    "compute_target = create_compute(gpu_compute_target, gpu_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1698781547772
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# For job\n",
    "env_name = \"detectron2-env@latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1698781550742
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input\n",
    "from azure.ai.ml import command, Input, MLClient, UserIdentityConfiguration, ManagedIdentityConfiguration\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "# Load from local\n",
    "data_path = r\"\"\n",
    "\n",
    "# Load from Azure container\n",
    "data_path = r\"\"\n",
    "\n",
    "# If Azure container, you may need identity\n",
    "identity = UserIdentityConfiguration() # Use the user's identity\n",
    "# identity = ManagedIdentityConfiguration() # Use the compute target managed identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1698781560134
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# Set job and run\n",
    "job = command(\n",
    "     code=\".\",  \n",
    "     command='python detectron2_train.py --traindata ${{inputs.train_data}} --epochs ${{inputs.epochs}} --learning_rate ${{inputs.learning_rate}} --img_per_batch ${{inputs.img_per_batch}} --roi_batch_size ${{inputs.roi_batch_size}} --roi_batch_size ${{inputs.rescale}}' ,\n",
    "     inputs={\n",
    "         \"train_data\": Input(path=data_path,\n",
    "             type=AssetTypes.URI_FOLDER,\n",
    "             mode=InputOutputModes.RO_MOUNT # Mount (.RO_MOUNT) or download (.DOWNLOAD)\n",
    "         ),\n",
    "         \"epochs\": 10, # iterations / epoch = num_train_images / img_per_batch\n",
    "         \"learning_rate\": 0.0025,\n",
    "         \"gamma\": 0.01, # reduce learning rate at 2/5, 3/5 and 4/5 of the iterations\n",
    "         \"img_per_batch\": 4, # the real \"batch size\"\n",
    "         \"roi_batch_size\": 16, # the ROI head \"batch size\"\n",
    "         \"rescale\": 224,\n",
    "     },\n",
    "     compute=compute_target,\n",
    "     environment=env_name,\n",
    "     identity=identity,\n",
    "     outputs={},  # Add any required outputs here\n",
    "     description=\"Detectron2 training.\"\n",
    " )\n",
    "\n",
    "# ml_client.jobs.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "\n",
    "num_epochs = 1 # Iterations over entire training dataset\n",
    "\n",
    "job_for_sweep = job(\n",
    "    epochs=Choice(values=[num_epochs]),\n",
    "    learning_rate=Uniform(min_value=0.0001, max_value=0.01),\n",
    "    gamma=Uniform(min_value=0.01, max_value=0.1),\n",
    "    img_per_batch=Choice(values=[2,3,5]),\n",
    "    roi_batch_size=Choice(values=[4, 8, 16, 64, 128]),\n",
    "    rescale=Choice(values=[538])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = job_for_sweep.sweep(\n",
    "    compute=compute_target,\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"epoch_loss\",\n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "\n",
    "# define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=1)\n",
    "\n",
    "# define stopping policy\n",
    "# sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation = int(num_epochs/4), evaluation_interval = int(num_epochs/4))\n",
    "\n",
    "# submit the sweep\n",
    "ml_client.create_or_update(sweep_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
